Hello all, my name is Krishna and (0.48) welcome to my YouTube channel. So guys, (2.56) today in this particular video we are (4.48) going to discuss about the basic (6.16) differences between generative AI versus (7.839) AI agents versus agentic AI. Now this is (10.32) one of the most trending topics that is (13.679) currently going on and it is necessary (15.839) that you need to have your understanding (17.6) very much clear when you are (20.24) specifically working in all the specific (22.08) topics. Okay. So one by one we will try (24.0) to understand about each and every (27.199) topics that I have actually mentioned (29.039) over here. We'll go step by step. Okay. (30.32) So first thing is that I hope you may be (32.8) knowing large language models. Okay. You (35.12) may be knowing about large image models (37.84) also. Right? So let's say that I'll also (40.719) go ahead and write large image models. (43.28) When we talk about large language models (45.76) or large image model, these models are (47.52) actually very huge models, right? These (51.44) are like huge models, bigger models, (54.64) right? It can be of billions of (56.879) parameters and they have trained with (58.8) huge amount of data, right? This data (61.199) that it is specifically used to train (63.92) this model is huge. So you may have seen (65.76) various models like llama 3. You may (68.32) have been seeing OpenAI models right (71.36) from GPT4 to GPT4 mini. Many many (73.439) different models are there. And these (77.439) models are specifically trained with (78.72) huge amount of data. And at the end of (80.24) the day, all these particular models are (82.72) generating what are they basically (86.04) doing? They're generating new content, (88.159) right? Generating new (90.36) content. Now, when we talk about (93.24) generating new content, the models can (95.36) probably generate new (97.92) images, it can generate new text, it can (99.96) generate video frames, it can generate (103.32) anything as such, right? (106.24) audio it can also generate audio right (108.479) and it can also generate videos so I've (111.68) written each and everything about over (113.84) here right so here what this LLM is (115.439) basically doing since it is trained with (118.399) huge amount of data in short it is (119.92) basically generating new content (122.32) whenever we try to give any kind of (123.759) input right if I say hey please generate (125.759) a new image related to aentic AI so this (128.16) LLA model it if it has that multimodel (131.12) capabilities it will be able to generate (134.0) that particular image or video whatever (136.0) specific things we require whenever we (138.239) talk in this specific way this is (140.56) something related to generative AI okay (142.56) so this is something related to (145.28) generative AI right now when we say hey (146.879) uh let's go ahead and build a generative (150.08) AI application wherein we create a (151.68) chatbot okay and that chatbot should be (155.08) able to do this specific ch uh task (158.48) wherein the main aim is generating new (161.599) content you can definitely do it right (163.84) so There we specifically say hey we are (166.4) specifically working in generative AI (168.72) applications right here the most (170.56) important thing is that there's some few (173.76) properties that everybody should keep in (176.0) mind right whenever we talk about (177.92) generative AI application these are (179.68) specifically (182.319) reactive okay reactive there is this (183.64) word that we use which we basically say (186.48) it as reactive now what does this (188.8) basically reactive mean right see in (191.04) order to work with this LLM models right (195.12) we definitely have to write some kind of (197.599) prompts okay prompts and based on this (200.36) particular prompt this LLM model will (204.319) generate new content this is really (206.56) important to understand now what does (208.56) this prompt basically means this prompt (210.64) is just like some sentence where we (213.44) specify something and we tell the LLM to (216.64) behave in that way I may say hey that uh (218.799) hey please try to uh act as a data (221.28) scientist and take an interview for me (224.64) right so I that is a kind of prompt that (226.879) is a kind of instruction that I'm (229.599) actually giving to the LLM model right (231.44) so here the most important thing with (234.159) respect to the generative AI content uh (236.48) generative AI application is that (238.4) obviously you will be having some kind (240.159) of models LLM models LM models (242.239) multimodel right along with these models (244.519) we specifically write prompts right like (247.28) how this particular LML model should be (249.84) behaving and that is how it'll go ahead (252.56) and generate the new content. Okay. So (254.799) this is with respect to the generative (257.04) AI applications. Right? Here uh there (258.56) are lot of different different kind of (261.68) libraries. There are libraries like (263.199) langraph right. There are libraries like (265.24) lang chain which you can specifically (268.16) use and you can get started with right (270.16) lang chain. There are different (273.199) different libraries like let's say llama (274.72) index. Llama index right? If you don't (276.919) want to go ahead and use this you can (280.639) also go ahead and use grock. Grock also (282.0) has a specific set of code or you can (285.04) also go ahead and use OpenAI code in (288.08) order to probably go ahead and start (290.32) working and developing geni (291.919) applications. Okay. Now this is one of (293.44) the thing. Okay. Now the next two topics (295.68) that we are specifically going to (298.72) discuss about is something called as AI (300.08) agents and agentic AI. And this is super (302.16) important right now because the thing (304.6) that we work on right agentic AI (307.12) application it is trending in every (309.12) field. people are thinking that how they (311.199) can automate the entire complex task the (313.44) entire workflow with the help of agent (316.32) application and obviously bring human (318.479) feedback in between them. Okay. Now (320.479) let's go ahead and discuss about this (322.88) and I hope I have already made a video (324.4) related to generative way. I have (326.4) developed so many different videos from (327.759) lang chain to lang graph you can (329.68) definitely go ahead and watch. (331.199) Okay. Now let's go ahead and discuss (333.16) about the second thing which is nothing (335.44) but the second category that we're going (337.08) to focus on is AI (339.84) agents versus agentic (342.68) AI versus agentic (345.96) AI. Now people do think that AI agents (349.639) and agentic AI one and the same but it (354.32) is not like that. Okay. So here just (356.96) please focus on for the next 10 minutes (360.639) because I'm going to explain each and (362.96) everything that you really need to (364.56) understand and that is how you'll be (366.319) able to understand between what is the (368.0) basic difference between AI agents and (369.52) agent AI. Okay. Now let's say that I (371.36) have some kind of LLMs. Okay. So let's (374.96) say and at all these places LLM is the (377.36) most important thing right because LLM (380.56) is something that will be acting like an (382.639) AI agent. It can act like an AI agent. (385.36) it can also work in an agentic AI (387.28) application. Okay. And it will it will (389.36) be very important how this AI agents is (391.28) different when compared to the LLM also. (394.16) Okay. So let's say that I have a (396.479) specific LLM. Okay. And now this LLM can (399.12) be any model. Okay. Let's let's consider (401.52) that it is it is some model that we are (403.52) going to use from graph. It can be lama (406.16) 3. We are using this specific model. (408.08) Okay. Now you know that all these LLM or (410.4) LM models they're trained with some (413.44) specific past data okay they don't have (415.52) like let's say if I ask this particular (419.12) LLM hey what is the news for today or (420.84) hey or who won this particular IPL match (424.319) between this and this like let's say (427.52) Bangalore is going to happen have some (429.599) matches tomorrow or today if it has (431.639) right and LLM will not know the result (434.4) because it's not connected to the (436.96) internet okay so in that kind of (438.4) scenario Whenever I ask this particular (440.4) question, the LLM will not be able to (442.24) give an output to us. Okay, obviously it (444.0) will not be able to give because it does (447.199) not have that specific information. Now, (448.72) this is one major disadvantage of LLM, (451.44) right? Yes, LLM will be able to generate (454.24) new content. These models will be able (456.72) to generate the new content. But what (458.319) about the current information? Okay, it (460.0) will not be able to give you, right? (461.84) Let's say that I'm going to ask some (464.16) specific information of a company. (466.16) Obviously this LLM will not be trained (468.479) with that company data because the (470.4) company data will be private to that (472.16) company itself. Right? So that way also (473.759) that LLM will not be able to give you (476.16) that unless and until it is connected to (477.84) some kind of external database or (479.759) external data source. This is just one (481.52) example now what is basically happening (483.879) is that as soon as I asked a question (486.16) hey who won this particular match within (487.759) RCB or any other place any other um any (489.68) other team that happened today it will (493.199) not be able to give you the output. So (495.52) what it will be dependent on it will be (497.759) dependent on the third party source. (499.36) Let's say there is one third party (502.16) source I will consider in this (503.52) particular scenario. I will just go (505.12) ahead and connect it to some kind of (507.12) database. Okay. Let's say one of the (509.36) data source is something called as taby. (511.84) I will go ahead and write tabi. So if (514.64) you don't know about tabi it provides (516.719) you some kind of internet search. Okay. (518.56) It you can use that particular API. You (520.88) can write this specific wrapper and you (522.959) can probably go ahead and write this. (524.8) Now the question arises how this llm is (526.64) basically going to call this tavly API. (529.839) Now there is one very important property (532.48) if you're learning lang chain or lang (534.48) graph any of the specific libraries (536.16) there is a concept of something called (538.48) as tool call. Tool (540.0) call. Okay tool call. Now what is this (543.0) tool call? Let's say that if the LLM is (546.64) not able to provide the response for (548.72) this particular input, it will keep on (550.88) looking for external things that will be (553.36) able to handle this particular input. (555.839) Now in this particular case when I ask (558.0) the input saying that hey what is the (560.16) current news? What is the current news (562.08) for this specific date that is today's (564.72) date? The LLM will not be able to give (566.8) the answer. So the LLM will look for (568.8) whether it is connected to any (571.44) third-party APIs, third party APIs or (573.16) data source from which I will be able to (577.04) get this kind of information. So that is (579.04) where it will be making the specific (581.68) tool call. Okay, it will be making the (584.32) specific tool call. Now this tool call (587.279) will be something like this. The tool (588.959) call will be made and based on this I (590.399) will be getting a response. Okay, I'll (592.399) be getting a response. Now the as soon (595.68) as the LLM made this tool call the it (598.08) got this specific response. So this is (601.519) my request and this is my response. (603.36) Okay, this is my response and as soon as (606.04) I got the response the LLM is smart (609.279) enough to finally summarize that (611.6) particular output uh that response and (613.68) give you the output and this is what I'm (616.0) actually looking for. Okay. (617.92) Now you need to really understand over (620.56) here the kind of task that is happening (622.839) right a request is going I'm getting the (626.32) information I'm getting giving back the (628.56) response this is basically happening by (630.44) an AI agent just a single AI agent I can (633.2) consider this as an AI agent okay here (636.8) my main aim is that I have asked an (640.0) input saying that hey give me the some (642.56) current information about today AI news (644.399) I really want to see for this particular (647.839) date AI news which my LLM was not able (650.16) to do it. So what it has done is that (652.24) the LLM is smart enough to understand (654.24) which tool to probably call and based on (656.32) this tool call functional it is calling (658.72) this and it is getting the response. So (660.24) this is a specific task okay and this (662.32) task is basically solved by this tavly (665.36) okay tavly which is responsible for the (667.76) internet search. So this task can be (669.68) considered as an AI agent. Okay, for a (672.88) specific task we have defined this. (675.2) Okay, very simple definition. Okay, so (677.279) for a specific task we are able to (679.92) probably go ahead and call this and we (681.6) are getting the response. Now the (682.959) question rises, now the question (684.56) rises then what is agentic AI? AI agents (687.48) have understood okay fine for a specific (691.04) task I'm calling something from the LLM, (693.12) right? The LM is responsible for making (695.44) that tool call and getting the output (697.519) and summarizing the output and giving it (699.12) over here. Here also we can add the (700.8) prompt. Here also once I get the (702.48) response I can add the prompt and based (704.959) on that I can summarize the output. I (707.279) can do that. Okay. But this is only for (709.12) one kind of task. Now if I talk about (711.2) agentic AI okay and for discussing about (713.839) the agentic AI application let's (716.399) consider that let's consider that I have (718.0) a task and this task is nothing but (720.64) let's consider I want to probably (723.839) convert a YT video that I really want to (725.92) upload to a (728.48) blog (730.44) okay to a blog and now to convert a YT (732.12) video YouTube video into a blog let's (736.959) say that I have been uploading so many (740.079) videos. Just imagine if I just create an (742.16) agenti system which takes my YouTube (744.32) video and convert that into a blog and (746.72) publish it in my website. Would it will (748.8) that not be good? It will definitely be (751.04) good. Right now here if I probably see I (753.04) can divide this into multiple subtask. (755.76) First of all I will take this YT video. (757.68) I will convert I will take the (760.399) transcript from the YT video. Transcript (762.48) from the YT video. Okay. After (765.76) considering the transcript from this my (768.639) second task will be creating (771.04) title. Creating title. Okay. Third it (773.8) can be creating (778.0) description. Okay. So this will be my (780.839) third task creating (782.959) description and my fourth task will be (785.24) writing the (787.839) conclusion. Let's say so I've defined (789.16) this task into four different task right (791.6) four different tasks. Now for the same (794.959) task, don't you think converting a (796.88) YT YT video into transcript, I can (801.16) create one AI agent. Then similarly for (805.44) my second AI agent, I can basically take (809.12) this transcript (811.839) and this AI agent should be able to give (813.399) me the title. Yeah. Yeah. And just to (816.639) show you how these things will happen, (820.24) don't you think I can just go ahead see (822.639) this? Okay, see this magic. Okay. So, so (825.839) what what I will be doing is that my (827.92) first task will be that this AI agent (829.76) will be responsible in getting me the (832.24) transcript from my YouTube video. Okay. (834.56) This AI agent will be responsible for (836.48) creating the title from the transcript (839.04) that I get. Okay. Then my next agent (841.12) over here which will be parallelly will (844.48) be (846.8) responsible to probably create the (847.56) description from this particular (849.839) transcript. Yeah. And finally, don't you (851.399) think I can have one more one (854.56) more AI agent which will be responsible (858.04) in creating the conclusion. Right? Now (862.72) here this is my AI agent one. Let's (866.44) consider this. Okay. So this is my AI (870.48) agent (873.68) one. This is my AI agent (875.56) 2. This is my AI agent three. And this (879.72) is my AI agent (884.88) 4. Each and every agent can use LLM. It (887.0) can use (892.56) prompt to perform its task. Each each (895.0) here it can or it cannot it is not (900.0) composite it needs to use all the LLM (902.959) but since we are working with respect to (905.199) text related things then obviously we (907.12) can use LLM okay for now this is just (909.839) like a one kind of workflow so this (912.8) workflow goes on like this right so (915.199) first of all I give my YT video (916.88) URL YT video URL then this agent is (920.199) responsible in taking from this and (923.839) giving the output a (926.24) transcript. Now this transcript is sent (928.44) to all the agents and finally we can (932.639) combine all these (937.04) outputs and give my final (939.8) blog. Right? So what does this basically (943.32) mean? Before an AI agent only used to do (946.48) one task in an agentic AI system. So (949.839) this is my entire complex workflow with (953.04) respect to my agentic AI system and this (956.72) is performing this entire task together. (960.56) Here every agent is communicating with (964.68) each other. Right? I can add one more (967.6) thing over here. I can add human (970.639) feedback. Human feedback also over (973.399) here. So here what is basically (976.36) happening? AI agents are communicating (978.72) with each other. (981.12) Right. I can also make sure to probably (982.72) before this AI agent, let's say this (985.839) agent is responsible in probably (987.759) creating a description. For creating a (989.36) description, it also wants the title. So (991.68) it will just go ahead this AI agent 2 (993.6) whatever output it is creating for the (996.16) title, it will give it to the agent 3. (998.0) And this will take that information and (1000.24) do this. So internally you'll be able to (1002.079) see we can also make this agent (1004.399) communicate with each other to solve a (1006.639) complex workflow and finally achieve a (1010.16) goal. Right? So just to understand what (1013.44) is the difference between AI agents (1016.56) versus agentic AI here AI agent is doing (1017.839) only one task. In an agentic AI system (1020.24) this AI agents will be collaborating (1023.36) with each other. This is really (1025.6) important. (1026.959) Collaborating (1029.559) collaborating with each (1031.4) other to solve a (1034.6) goal. This is really really important to (1037.959) understand. So I hope you understood (1041.64) this particular video. I hope you liked (1044.16) this particular video. This was the (1046.0) basic differences between generative AI (1047.679) versus AI agent versus agentic AI. And I (1049.52) hope you are able to understand this. (1052.32) Okay. Similar kind of videos I'm also (1054.16) going to come up in this specific series (1056.4) so that you get your fundamental rights. (1058.24) I hope you like this particular video. (1060.72) This was it from my side. I'll see you (1062.24) in the next video. Have a great day. (1063.6) Thank you and all. Take care. Bye-bye. (1064.96)