{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a2c00b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from testing_folder.utility_functions import * \n",
    "def load_embeddings_faiss(thread_id: str):\n",
    "    embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "    save_dir = f\"faiss_indexes/{thread_id}\"\n",
    "\n",
    "    if not os.path.exists(save_dir):\n",
    "        raise ValueError(f\"No FAISS index found for thread_id: {thread_id}\")\n",
    "\n",
    "    vector_store = FAISS.load_local(save_dir, embeddings, allow_dangerous_deserialization=True)\n",
    "    retriever = retriever_docs(vector_store)\n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f54884ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='f2129db9-0216-4712-956b-746518353e87', metadata={}, page_content='like how things are (3426.96) basically happening over here right now (3429.119) uh what we can do is that see if you (3432.0) know if you have created all these (3434.799) things right till here you have created (3436.16) now the further step is that you to just (3438.4) integrate LLM with the uh with this (3440.48) specific context. Okay. Now for this LLM (3442.96) with this specific context, what you can (3446.48) do is that you can directly take this (3448.079) particular context and give it to the (3450.0) LLM and that is what we are going to see (3451.2) in the next video. But in this (3453.28) particular video, we saw the entire (3454.96) thing the complete rack pipeline from (3457.359) data injection to the vector DB (3459.52) pipeline. Right now you can go ahead and (3461.04) write any kind of queries and definitely (3463.119) with all these information here you can (3466.0) see similarity score is also coming up (3467.599) right distance is also basically coming (3469.839)'),\n",
       " Document(id='e029bb8a-fc10-4843-a9f1-f7ab539513f6', metadata={}, page_content=\"as a mapping a query as a (3342.96) set of this one and this entire thing is (3344.8) basically the context. So from this (3347.2) particular diagram here you can see (3349.76) easily we are able to get the context (3351.44) right and this is nothing but this is (3353.28) your context. Now let's try some more (3355.44) things. Okay I will just go ahead and (3357.52) open some PDF. Okay. Um (3360.16) this is some very new research paper (3364.16) embedding technical report. Okay. Uh (3366.799) we'll search for any topic over here. Uh (3369.44) embedding model training. I'll just go (3372.559) ahead and search for unified multitask (3374.4) learning framework. Okay. because this (3376.64) information also we have put it over (3378.24) there. So here I'll go ahead and create (3379.68) one more this one and I will copy this (3383.119) entire code. Okay, quickly (3385.92) and this is the query that I'm actually (3389.839) going to give that is nothing but (3391.76) unified (3394.319) multi\"),\n",
       " Document(id='a8150a51-3fed-47d4-a144-0a154f41d00e', metadata={}, page_content=\"apply embeddings and from the (377.84) embeddings we finally store that into (379.759) our vector DB. Now inside this vector DB (382.08) all this will be stored in the form of (385.199) vectors like let's say this is my record (387.28) one record two record three record four (389.039) like that right so this is one record (393.6) two record this is my third record then (395.759) fourth record fifth record this you have (397.52) right now from this particular vector DB (399.84) you will definitely be able to apply any (403.68) kind of similarity search similarity (406.479) search now in this specific video what (409.68) we are going to do is that I will be (412.88) using any of this file and I'll create (415.6) this entire pipeline. Okay, I will I'll (418.24) just create this entire pipeline and you (421.039) also need to probably work along with me (424.88) later on. For any other files, I will (427.84) give you an assignment. Okay, I will (430.88) show you with couple of files. Let's\")]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = load_embeddings_faiss(\"part 1 krisnaik\")\n",
    "user_question = \"What is this video about\"\n",
    "retrieved_chunks = retriever.get_relevant_documents(user_question)\n",
    "retrieved_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee9a8f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'like how things are (3426.96) basically happening over here right now (3429.119) uh what we can do is that see if you (3432.0) know if you have created all these (3434.799) things right till here you have created (3436.16) now the further step is that you to just (3438.4) integrate LLM with the uh with this (3440.48) specific context. Okay. Now for this LLM (3442.96) with this specific context, what you can (3446.48) do is that you can directly take this (3448.079) particular context and give it to the (3450.0) LLM and that is what we are going to see (3451.2) in the next video. But in this (3453.28) particular video, we saw the entire (3454.96) thing the complete rack pipeline from (3457.359) data injection to the vector DB (3459.52) pipeline. Right now you can go ahead and (3461.04) write any kind of queries and definitely (3463.119) with all these information here you can (3466.0) see similarity score is also coming up (3467.599) right distance is also basically coming (3469.839)'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_chunks[0].page_content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
