{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2ddec67",
   "metadata": {},
   "source": [
    "# Topic TimeStamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8add5b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.prompts import (\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    ChatPromptTemplate,\n",
    ")\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "# -------------------------\n",
    "# 1) Pydantic output schema\n",
    "# -------------------------\n",
    "class Subtopic(BaseModel):\n",
    "    subtopic: str = Field(description=\"Short name or description of the subtopic\")\n",
    "    content: str = Field(description=\"Brief summary of the subtopic\")\n",
    "    timestamp: float = Field(description=\"Approx timestamp in seconds where this subtopic is discussed\")\n",
    "    importance: Optional[str] = Field(default=None, description=\"Optional importance: high/medium/low\")\n",
    "\n",
    "class MainTopic(BaseModel):\n",
    "    topic: str = Field(description=\"Main topic name or short description\")\n",
    "    content : str = Field(description=\"Brief summary of the main topic\")\n",
    "    timestamp: float = Field(description=\"Approx timestamp in seconds where the main topic starts\")\n",
    "    subtopics: List[Subtopic] = Field(description=\"List of subtopics under this main topic\")\n",
    "\n",
    "class TopicsOutput(BaseModel):\n",
    "    main_topics: List[MainTopic] = Field(description=\"List of main topics with subtopics and timestamps\")\n",
    "\n",
    "# Create parser to enforce output JSON matches schema\n",
    "parser = PydanticOutputParser(pydantic_object=TopicsOutput)\n",
    "format_instructions = parser.get_format_instructions()\n",
    "\n",
    "# -------------------------\n",
    "# 2) System message prompt\n",
    "# -------------------------\n",
    "system_message = SystemMessagePromptTemplate.from_template(\n",
    "    \"\"\"You are an expert in analyzing and structuring video transcripts.\n",
    "\n",
    "You will receive a transcript of a YouTube video with timestamps.\n",
    "\n",
    "Your task is to:\n",
    "1. Extract all MAIN TOPICS discussed in the transcript.\n",
    "2. For each MAIN TOPIC, list its SUBTOPICS in a hierarchical structure.\n",
    "3. Always include timestamp references (in seconds) for both MAIN TOPICS and SUBTOPICS.\n",
    "4. For each subtopic, optionally add an 'importance' (high/medium/low) if it is clearly emphasized.\n",
    "5. Be concise and only include material that is actually discussed in the transcript.\n",
    "6. Output must be valid JSON and match the schema instructions below.\n",
    "\n",
    "REQUIRED OUTPUT FORMAT:\n",
    "{format_instructions}\n",
    "\n",
    "Transcript (will be supplied by the user below).\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# ---------------------------------------\n",
    "# 3) Human prompt (we supply the transcript)\n",
    "# ---------------------------------------\n",
    "human_message = HumanMessagePromptTemplate.from_template(\n",
    "    \"\"\"Transcript:\n",
    "{transcript}\n",
    "\n",
    "Notes:\n",
    "- Use timestamps in seconds (floats allowed).\n",
    "- Only include main topics and subtopics actually present in the transcript.\n",
    "- If something is unclear, omit it rather than inventing timestamps.\n",
    "\n",
    "Now extract main topics and subtopics.\"\"\"\n",
    ")\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message, human_message])\n",
    "\n",
    "# -------------------------\n",
    "# 4) VertexAI model config\n",
    "# -------------------------\n",
    "# Make sure GOOGLE_APPLICATION_CREDENTIALS env var is set to your service account json file.\n",
    "# The langchain VertexAI wrapper will pick up credentials automatically.\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0)\n",
    "# -------------------------\n",
    "# 5) Runner function\n",
    "# -------------------------\n",
    "def extract_topics_from_transcript(transcript: str) -> TopicsOutput:\n",
    "    prompt = chat_prompt.format_prompt(transcript=transcript, format_instructions=format_instructions)\n",
    "    messages = prompt.to_messages()\n",
    "\n",
    "    response_message = model.invoke(messages)\n",
    "    raw_output = response_message.content\n",
    "\n",
    "    # If content is a list â†’ join into a single string\n",
    "    if isinstance(raw_output, list):\n",
    "        raw_output = \" \".join(raw_output)\n",
    "\n",
    "    # Remove markdown fences like ```json ... ```\n",
    "    clean_output = raw_output.strip()\n",
    "    if clean_output.startswith(\"```\"):\n",
    "        clean_output = clean_output.strip(\"`\")\n",
    "        # Sometimes model outputs like ```json\\n{...}\\n``` so split off first line\n",
    "        clean_output = clean_output.split(\"\\n\", 1)[-1]\n",
    "\n",
    "    # Parse into Pydantic object\n",
    "    return parser.parse(clean_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "912de3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import re\n",
    "def load_transcript(url: str) -> str | None:\n",
    "    \"\"\"\n",
    "    Fetch transcript for a YouTube video.\n",
    "    \"\"\"\n",
    "    pattern = r'(?:v=|\\/)([0-9A-Za-z_-]{11})'\n",
    "    match = re.search(pattern, url)\n",
    "    if match:\n",
    "        video_id = match.group(1)\n",
    "        try:\n",
    "            captions = YouTubeTranscriptApi().fetch(video_id,languages=['en','hi']).snippets\n",
    "            data = [f\"{item.text} ({item.start})\" for item in captions]\n",
    "            return \" \".join(data)\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error fetching transcript: {e}\")\n",
    "            return None\n",
    "from dataclasses import dataclass\n",
    "@dataclass\n",
    "class TimestampedSegment:\n",
    "    \"\"\"Represents a segment of transcript with timestamp\"\"\"\n",
    "    text: str\n",
    "    start_time: float\n",
    "    end_time: float = None\n",
    "    \n",
    "def parse_transcript(transcript: str) -> List[TimestampedSegment]:\n",
    "\n",
    "        segments = []\n",
    "        \n",
    "        # Regular expression to find text and timestamps\n",
    "        # Pattern: captures text followed by timestamp in parentheses\n",
    "        pattern = r'(.*?)\\((\\d+\\.?\\d*)\\)'\n",
    "        \n",
    "        matches = re.findall(pattern, transcript)\n",
    "        \n",
    "        for i, (text, timestamp) in enumerate(matches):\n",
    "            text = text.strip()\n",
    "            if text:  # Only add non-empty text segments\n",
    "                segment = TimestampedSegment(\n",
    "                    text=text,\n",
    "                    start_time=float(timestamp),\n",
    "                    end_time=float(matches[i+1][1]) if i+1 < len(matches) else None\n",
    "                )\n",
    "                segments.append(segment)\n",
    "        \n",
    "        return segments\n",
    "\n",
    "captions = load_transcript(\"https://youtu.be/ikzN6byFNWw\")\n",
    "segments = parse_transcript(captions)\n",
    "formatted = []\n",
    "for segment in segments:\n",
    "    formatted.append(f\"[{segment.start_time}s] {segment.text}\")\n",
    "    \n",
    "output = extract_topics_from_transcript(\" \".join(formatted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c5c16e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TopicsOutput(main_topics=[MainTopic(topic='Introduction and Playlist Recap', content='The video starts with an introduction and a recap of the LangGraph Agentic AI playlist journey, covering theoretical concepts, practical LangGraph, and the development of a chatbot with features like GUI, streaming, and database persistence.', timestamp=0.0, subtopics=[Subtopic(subtopic='Playlist Journey Summary', content='A summary of the topics covered so far, from theoretical foundations to practical implementations.', timestamp=14.24, importance=None), Subtopic(subtopic='Chatbot Project Development', content='Overview of the chatbot developed, highlighting its current features.', timestamp=40.399, importance='medium'), Subtopic(subtopic='Chatbot Features', content='Specific features added to the chatbot, including a GUI, streaming, and database persistence for chat history.', timestamp=54.16, importance=None)]), MainTopic(topic='Introducing Observability with LangSmith', content='Introduction of a new, important feature: Observability, to be added to the chatbot using LangSmith. The speaker emphasizes its significance for LLM systems.', timestamp=90.0, subtopics=[Subtopic(subtopic='What is Observability?', content='A brief explanation of observability in the context of LLM systems, focusing on end-to-end tracing of chatbot execution.', timestamp=97.119, importance=None), Subtopic(subtopic='Recommended LangSmith Crash Course Video', content='Strong recommendation to watch a separate two-hour LangSmith crash course video for a detailed understanding of observability and the LangSmith tool.', timestamp=104.56, importance='high'), Subtopic(subtopic='Summary of Observability', content='A concise summary of observability as tracing chatbot execution, recording token usage, latency, and internal system workings.', timestamp=145.84, importance=None), Subtopic(subtopic='Benefits for Future Features', content='How observability will aid in understanding more complex features like tools and RAG (Retrieval Augmented Generation) in future videos.', timestamp=181.92, importance=None)]), MainTopic(topic='LangSmith Integration Setup', content='Detailed steps on how to integrate LangSmith with the existing LangGraph project, including account creation, API key generation, and environment variable configuration.', timestamp=204.48, subtopics=[Subtopic(subtopic='Create LangSmith Account and API Key', content='Instructions on visiting smith.langchain.com, creating an account, and generating an API key.', timestamp=206.879, importance=None), Subtopic(subtopic='Add Environment Variables', content=\"Explanation of the necessary environment variables (`LANGCHAIN_TRACING_V2`, `LANGCHAIN_ENDPOINT`, `LANGCHAIN_API_KEY`, `LANGCHAIN_PROJECT`) to be added to the project's environment file.\", timestamp=266.08, importance=None), Subtopic(subtopic='Automatic Tracing', content='Once environment variables are set, LangSmith automatically starts tracing the LangGraph project without further code changes.', timestamp=366.639, importance=None)]), MainTopic(topic='Basic LangSmith Tracing Demonstration (Without Threads)', content=\"Demonstration of LangSmith's basic tracing capabilities by running the chatbot and observing how interactions are recorded in the LangSmith dashboard.\", timestamp=358.639, subtopics=[Subtopic(subtopic='Running the Chatbot', content='Executing the existing chatbot code to generate interactions.', timestamp=383.199, importance=None), Subtopic(subtopic='Viewing Traces in LangSmith Dashboard', content='Navigating the LangSmith dashboard to see the newly created project and individual traces.', timestamp=433.68, importance=None), Subtopic(subtopic='Trace Organization and Details', content='Explanation of how LangSmith organizes traces at the project level, with each user turn captured as a separate trace, showing details like input, output, token usage, and latency.', timestamp=461.599, importance=None), Subtopic(subtopic='Problem: Unorganized Conversations', content='Identification of a limitation where all conversation turns, even from different threads, are stored as individual traces in one flat list, leading to potential disorganization.', timestamp=630.32, importance='high')]), MainTopic(topic='Implementing Thread-Based Organization in LangSmith', content=\"Addressing the organization problem by implementing LangSmith's thread feature, which allows grouping related traces into conversational threads.\", timestamp=704.72, subtopics=[Subtopic(subtopic='LangSmith Solution: Threads', content=\"Introduction of LangSmith's feature to organize traces into conversational threads for better management.\", timestamp=714.8, importance=None), Subtopic(subtopic='Code Changes for Threading', content='Explanation of the specific code modifications required to enable thread-based tracing, primarily by updating the `config` variable.', timestamp=757.519, importance=None), Subtopic(subtopic='Adding Metadata with Thread ID', content='Details on how to include `metadata` containing the `thread_id` in the configuration passed to the chatbot, allowing LangSmith to group traces.', timestamp=890.0, importance=None), Subtopic(subtopic='Optional: Adding Run Name for Readability', content=\"An optional enhancement to set a `run_name` (e.g., 'Chat Turn') for traces, improving readability in the LangSmith dashboard.\", timestamp=917.199, importance=None)]), MainTopic(topic='Demonstrating Thread-Based Tracing', content='Live demonstration of the improved LangSmith integration with thread-based organization, showing how conversations are now neatly grouped.', timestamp=983.6, subtopics=[Subtopic(subtopic='First Conversation with Threading', content=\"Initiating a conversation after implementing thread changes, observing the trace named 'Chat Turn' and the creation of a new thread in LangSmith.\", timestamp=1013.759, importance=None), Subtopic(subtopic='Continuing Conversation within Thread', content='Adding more messages to the ongoing conversation, demonstrating how subsequent turns are added as traces within the same thread.', timestamp=1063.28, importance=None), Subtopic(subtopic='Creating a New Conversation/Thread', content='Starting a completely new conversation to show how LangSmith creates a separate, distinct thread for it.', timestamp=1131.679, importance=None), Subtopic(subtopic='Viewing Multiple Threads and Detailed Analysis', content='Showcasing the LangSmith dashboard with multiple threads, allowing users to easily navigate and analyze individual turns (traces) within each conversation, including latency and token usage.', timestamp=1162.799, importance=None)]), MainTopic(topic='Conclusion and Future Scope', content='Concluding remarks on the importance of LangSmith for complex AI projects and production environments, with a look ahead at other features.', timestamp=1222.24, subtopics=[Subtopic(subtopic='Importance for Complex Features and Production', content=\"Reiterating that LangSmith's observability will be crucial for understanding and debugging more complex features like tools and RAG, and for production deployments.\", timestamp=1228.159, importance='high'), Subtopic(subtopic='Other LangSmith Features', content='Brief mention of other LangSmith features (monitoring, datasets, experiments, prompts, playground) that are covered in the recommended crash course video and may be discussed in future videos.', timestamp=1260.24, importance=None)])])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f4c447d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŽ¯ Main Topic 1: Introduction and Playlist Recap  â° 0.0\n",
      "                  The video starts with an introduction and a recap of the LangGraph Agentic AI playlist journey, covering theoretical concepts, practical LangGraph, and the development of a chatbot with features like GUI, streaming, and database persistence.\n",
      "----------------------------------------------------\n",
      "   ðŸ”¹ Subtopic 1.1: Playlist Journey Summary  â° 14.24 None\n",
      "                  A summary of the topics covered so far, from theoretical foundations to practical implementations.\n",
      "   ðŸ”¹ Subtopic 1.2: Chatbot Project Development  â° 40.399 medium\n",
      "                  Overview of the chatbot developed, highlighting its current features.\n",
      "   ðŸ”¹ Subtopic 1.3: Chatbot Features  â° 54.16 None\n",
      "                  Specific features added to the chatbot, including a GUI, streaming, and database persistence for chat history.\n",
      "====================================================\n",
      "\n",
      "ðŸŽ¯ Main Topic 2: Introducing Observability with LangSmith  â° 90.0\n",
      "                  Introduction of a new, important feature: Observability, to be added to the chatbot using LangSmith. The speaker emphasizes its significance for LLM systems.\n",
      "----------------------------------------------------\n",
      "   ðŸ”¹ Subtopic 2.1: What is Observability?  â° 97.119 None\n",
      "                  A brief explanation of observability in the context of LLM systems, focusing on end-to-end tracing of chatbot execution.\n",
      "   ðŸ”¹ Subtopic 2.2: Recommended LangSmith Crash Course Video  â° 104.56 high\n",
      "                  Strong recommendation to watch a separate two-hour LangSmith crash course video for a detailed understanding of observability and the LangSmith tool.\n",
      "   ðŸ”¹ Subtopic 2.3: Summary of Observability  â° 145.84 None\n",
      "                  A concise summary of observability as tracing chatbot execution, recording token usage, latency, and internal system workings.\n",
      "   ðŸ”¹ Subtopic 2.4: Benefits for Future Features  â° 181.92 None\n",
      "                  How observability will aid in understanding more complex features like tools and RAG (Retrieval Augmented Generation) in future videos.\n",
      "====================================================\n",
      "\n",
      "ðŸŽ¯ Main Topic 3: LangSmith Integration Setup  â° 204.48\n",
      "                  Detailed steps on how to integrate LangSmith with the existing LangGraph project, including account creation, API key generation, and environment variable configuration.\n",
      "----------------------------------------------------\n",
      "   ðŸ”¹ Subtopic 3.1: Create LangSmith Account and API Key  â° 206.879 None\n",
      "                  Instructions on visiting smith.langchain.com, creating an account, and generating an API key.\n",
      "   ðŸ”¹ Subtopic 3.2: Add Environment Variables  â° 266.08 None\n",
      "                  Explanation of the necessary environment variables (`LANGCHAIN_TRACING_V2`, `LANGCHAIN_ENDPOINT`, `LANGCHAIN_API_KEY`, `LANGCHAIN_PROJECT`) to be added to the project's environment file.\n",
      "   ðŸ”¹ Subtopic 3.3: Automatic Tracing  â° 366.639 None\n",
      "                  Once environment variables are set, LangSmith automatically starts tracing the LangGraph project without further code changes.\n",
      "====================================================\n",
      "\n",
      "ðŸŽ¯ Main Topic 4: Basic LangSmith Tracing Demonstration (Without Threads)  â° 358.639\n",
      "                  Demonstration of LangSmith's basic tracing capabilities by running the chatbot and observing how interactions are recorded in the LangSmith dashboard.\n",
      "----------------------------------------------------\n",
      "   ðŸ”¹ Subtopic 4.1: Running the Chatbot  â° 383.199 None\n",
      "                  Executing the existing chatbot code to generate interactions.\n",
      "   ðŸ”¹ Subtopic 4.2: Viewing Traces in LangSmith Dashboard  â° 433.68 None\n",
      "                  Navigating the LangSmith dashboard to see the newly created project and individual traces.\n",
      "   ðŸ”¹ Subtopic 4.3: Trace Organization and Details  â° 461.599 None\n",
      "                  Explanation of how LangSmith organizes traces at the project level, with each user turn captured as a separate trace, showing details like input, output, token usage, and latency.\n",
      "   ðŸ”¹ Subtopic 4.4: Problem: Unorganized Conversations  â° 630.32 high\n",
      "                  Identification of a limitation where all conversation turns, even from different threads, are stored as individual traces in one flat list, leading to potential disorganization.\n",
      "====================================================\n",
      "\n",
      "ðŸŽ¯ Main Topic 5: Implementing Thread-Based Organization in LangSmith  â° 704.72\n",
      "                  Addressing the organization problem by implementing LangSmith's thread feature, which allows grouping related traces into conversational threads.\n",
      "----------------------------------------------------\n",
      "   ðŸ”¹ Subtopic 5.1: LangSmith Solution: Threads  â° 714.8 None\n",
      "                  Introduction of LangSmith's feature to organize traces into conversational threads for better management.\n",
      "   ðŸ”¹ Subtopic 5.2: Code Changes for Threading  â° 757.519 None\n",
      "                  Explanation of the specific code modifications required to enable thread-based tracing, primarily by updating the `config` variable.\n",
      "   ðŸ”¹ Subtopic 5.3: Adding Metadata with Thread ID  â° 890.0 None\n",
      "                  Details on how to include `metadata` containing the `thread_id` in the configuration passed to the chatbot, allowing LangSmith to group traces.\n",
      "   ðŸ”¹ Subtopic 5.4: Optional: Adding Run Name for Readability  â° 917.199 None\n",
      "                  An optional enhancement to set a `run_name` (e.g., 'Chat Turn') for traces, improving readability in the LangSmith dashboard.\n",
      "====================================================\n",
      "\n",
      "ðŸŽ¯ Main Topic 6: Demonstrating Thread-Based Tracing  â° 983.6\n",
      "                  Live demonstration of the improved LangSmith integration with thread-based organization, showing how conversations are now neatly grouped.\n",
      "----------------------------------------------------\n",
      "   ðŸ”¹ Subtopic 6.1: First Conversation with Threading  â° 1013.759 None\n",
      "                  Initiating a conversation after implementing thread changes, observing the trace named 'Chat Turn' and the creation of a new thread in LangSmith.\n",
      "   ðŸ”¹ Subtopic 6.2: Continuing Conversation within Thread  â° 1063.28 None\n",
      "                  Adding more messages to the ongoing conversation, demonstrating how subsequent turns are added as traces within the same thread.\n",
      "   ðŸ”¹ Subtopic 6.3: Creating a New Conversation/Thread  â° 1131.679 None\n",
      "                  Starting a completely new conversation to show how LangSmith creates a separate, distinct thread for it.\n",
      "   ðŸ”¹ Subtopic 6.4: Viewing Multiple Threads and Detailed Analysis  â° 1162.799 None\n",
      "                  Showcasing the LangSmith dashboard with multiple threads, allowing users to easily navigate and analyze individual turns (traces) within each conversation, including latency and token usage.\n",
      "====================================================\n",
      "\n",
      "ðŸŽ¯ Main Topic 7: Conclusion and Future Scope  â° 1222.24\n",
      "                  Concluding remarks on the importance of LangSmith for complex AI projects and production environments, with a look ahead at other features.\n",
      "----------------------------------------------------\n",
      "   ðŸ”¹ Subtopic 7.1: Importance for Complex Features and Production  â° 1228.159 high\n",
      "                  Reiterating that LangSmith's observability will be crucial for understanding and debugging more complex features like tools and RAG, and for production deployments.\n",
      "   ðŸ”¹ Subtopic 7.2: Other LangSmith Features  â° 1260.24 None\n",
      "                  Brief mention of other LangSmith features (monitoring, datasets, experiments, prompts, playground) that are covered in the recommended crash course video and may be discussed in future videos.\n",
      "====================================================\n"
     ]
    }
   ],
   "source": [
    "# Nicely formatted display of main topics and subtopics\n",
    "for i, topics in enumerate(output.main_topics, 1):\n",
    "    print(f\"\\nðŸŽ¯ Main Topic {i}: {topics.topic}  â° {topics.timestamp}\")\n",
    "    print(f\"                  {topics.content}\")\n",
    "    print(\"----------------------------------------------------\")\n",
    "\n",
    "    for j, sub in enumerate(topics.subtopics, 1):\n",
    "        print(f\"   ðŸ”¹ Subtopic {i}.{j}: {sub.subtopic}  â° {sub.timestamp} {sub.importance}\")\n",
    "        print(f\"                  {sub.content}\")\n",
    "        \n",
    "\n",
    "    print(\"====================================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ebae98",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
