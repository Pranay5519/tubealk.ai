{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "57002328",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "import streamlit as st\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import re      \n",
    "            \n",
    "            \n",
    "# _-----------------------------------------------------FUNCTIONS FOR RAG----------------------------------------------\n",
    "\n",
    "# ------------------ Transcript Loader ------------------\n",
    "def load_transcript(url: str) -> str | None:\n",
    "    pattern = r'(?:v=|\\/)([0-9A-Za-z_-]{11})'\n",
    "    match = re.search(pattern, url)\n",
    "    if match:\n",
    "        video_id = match.group(1)\n",
    "        try:\n",
    "            captions = YouTubeTranscriptApi().fetch(video_id).snippets\n",
    "            # join text + start_time\n",
    "            data = [f\"{item.text} ({item.start})\" for item in captions]\n",
    "            return \" \".join(data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching transcript: {e}\")\n",
    "            return None\n",
    "\n",
    "# ------------------ Text Splitter ------------------\n",
    "def text_splitter(transcript):\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    return splitter.create_documents([transcript])\n",
    "\n",
    "# ------------------ Vector Store & Retriever  ------------------\n",
    "def generate_embeddings(chunks):\n",
    "    embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "    return FAISS.from_documents(chunks, embeddings)\n",
    "\n",
    "def retriever_docs(vector_store):\n",
    "    return vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "\n",
    "def format_docs(retrieved_docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "50de37cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ Imports ------------------\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import TypedDict, Annotated\n",
    "import re\n",
    "import os\n",
    "from langchain.prompts import PromptTemplate\n",
    "#os.environ[\"LANGCHAIN_PROJECT\"] = \"TubeTalkAI Testing\"\n",
    "\n",
    "# ------------------ Build LLM (Gemini) ------------------\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0)\n",
    "\n",
    "#--------------------Prompt Template----------------------\n",
    "template = \"\"\"\n",
    "You are the YouTuber from the video, directly answering the viewer’s question.\n",
    "\n",
    "Rules:\n",
    "1. ONLY use the transcript provided below.\n",
    "2. Give the answer in simple, clear sentences — without timestamps inside the text.\n",
    "3. ALWAYS return the exact timestamp (in seconds) from the transcript line you used.\n",
    "   - Do NOT round or estimate timestamps.\n",
    "   - If multiple transcript parts are relevant, return the most direct one.\n",
    "4. Do NOT add greetings, filler, or extra commentary.\n",
    "5. If the transcript does not answer, say: \"Sorry, I didn’t talk about that in this video.\"\n",
    "\n",
    "Transcript:\n",
    "{transcript}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Output format (for schema):\n",
    "- \"answer\": A list of 1–3 short strings that directly answer the question (no timestamps here).\n",
    "- \"timestamps\": The exact timestamp (in seconds) from the transcript where the answer was found.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"transcript\", \"question\"],\n",
    "    template=template,\n",
    ")\n",
    "# ------------------ Structured Output Schema ------------------\n",
    "class AnsandTime(BaseModel):\n",
    "    answer:str = Field(\n",
    "        description=\"Answers to user's question (do NOT include timestamps here)\"\n",
    "    )\n",
    "    timestamps: float = Field(\n",
    "        description=\"The time (in seconds) from where the answer is taken\"\n",
    "    )\n",
    "\n",
    "structured_model = model.with_structured_output(AnsandTime)\n",
    "\n",
    "# ------------------ ChatState ------------------\n",
    "class ChatState(TypedDict):\n",
    "    messages: Annotated[list[BaseMessage], \"add_messages\"]\n",
    "\n",
    "# ------------------ Chat Node ------------------\n",
    "def chat_node(state: ChatState):\n",
    "    # Extract user question from state\n",
    "    user_message = state[\"messages\"][-1].content  # last message is the user's input\n",
    "\n",
    "    # Fill the prompt\n",
    "    final_prompt = prompt.format(\n",
    "        transcript=youtube_captions,   # <-- your transcript goes here\n",
    "        question=user_message\n",
    "    )\n",
    "\n",
    "    # Get structured output\n",
    "    response = structured_model.invoke(final_prompt)\n",
    "    ai_text = f\"{response.answer}\\nTimestamp: {response.timestamps}\"\n",
    "\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            state[\"messages\"][-1],  # include the HumanMessage again\n",
    "            AIMessage(content=ai_text)  # add the AI reply\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# ------------------ Build Graph ------------------\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "graph = StateGraph(ChatState)\n",
    "graph.add_node(\"chat_node\", chat_node)\n",
    "graph.add_edge(START, \"chat_node\")\n",
    "graph.add_edge(\"chat_node\", END)\n",
    "\n",
    "CONFIG = {'configurable': {'thread_id': \"newthread\"}}\n",
    "workflow =graph.compile(checkpointer = checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "638d3f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript Loaded: In January 2024, Google DeepMind released an AI model called Alpha Geometry, (0.0) which could solve geometry problems from the International Mathematical Olympiad, (5.079) or the IMO. (10.558) The IM ...\n"
     ]
    }
   ],
   "source": [
    "# ------------------ Load YouTube Transcript ------------------\n",
    "youtube_input = \"https://www.youtube.com/watch?v=4NlrfOl0l8U&t\"\n",
    "youtube_captions = load_transcript(youtube_input)\n",
    "print(\"Transcript Loaded:\", youtube_captions[:200], \"...\")\n",
    "\n",
    "# Split & Embed transcript\n",
    "chunks = text_splitter(youtube_captions)\n",
    "vector_store = generate_embeddings(chunks)\n",
    "retriever = retriever_docs(vector_store)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1298d821",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict = {\"human\": [], \"ai\": []}\n",
    "CONFIG = {'configurable': {'thread_id': \"newthread\"}}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3e981c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user : what is this Video About\n",
      "AI: This video is about AI and geometry, and how a non-AI model was already better at geometry than most humans.\n",
      "Timestamp: 80.44\n"
     ]
    }
   ],
   "source": [
    "while True : \n",
    "    user_input = input(\"User : \")\n",
    "    if user_input == 'exit':\n",
    "        break\n",
    "    print(\"user :\", user_input)\n",
    "    retrieved_chunks = retriever.get_relevant_documents(user_input)\n",
    "    context = format_docs(retrieved_chunks)\n",
    "    result = workflow.invoke(\n",
    "            {'messages': [HumanMessage(content=user_input)]},\n",
    "            config=CONFIG,\n",
    "        )\n",
    "    for msg in result['messages']:\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            if msg.content not in output_dict['human']:\n",
    "                output_dict['human'].append(msg.content)\n",
    "        elif isinstance(msg, AIMessage):\n",
    "            if msg.content not in output_dict['ai']:\n",
    "                output_dict['ai'].append(msg.content)\n",
    "\n",
    "    print(\"AI:\", output_dict['ai'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1ee1db41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'human': ['what is this Video About'],\n",
       " 'ai': ['This video is about AI and geometry, and how a non-AI model was already better at geometry than most humans.\\nTimestamp: 80.44']}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "dc17969d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eo is about AI and geometry, and how a non-AI model was already better at geometry than most humans.\n",
      "Timestamp: 80.44\n"
     ]
    }
   ],
   "source": [
    "print(output_dict['ai'][-1][8:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "99ab9281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='what is this Video About', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='This video is about AI and geometry, and how a non-AI model was already better at geometry than most humans.\\nTimestamp: 80.44', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['messages']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
