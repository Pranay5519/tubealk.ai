{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "57002328",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "import streamlit as st\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import re      \n",
    "            \n",
    "            \n",
    "# _-----------------------------------------------------FUNCTIONS FOR RAG----------------------------------------------\n",
    "\n",
    "# ------------------ Transcript Loader ------------------\n",
    "def load_transcript(url: str) -> str | None:\n",
    "    pattern = r'(?:v=|\\/)([0-9A-Za-z_-]{11})'\n",
    "    match = re.search(pattern, url)\n",
    "    if match:\n",
    "        video_id = match.group(1)\n",
    "        try:\n",
    "            captions = YouTubeTranscriptApi().fetch(video_id).snippets\n",
    "            # join text + start_time\n",
    "            data = [f\"{item.text} ({item.start})\" for item in captions]\n",
    "            return \" \".join(data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching transcript: {e}\")\n",
    "            return None\n",
    "\n",
    "# ------------------ Text Splitter ------------------\n",
    "def text_splitter(transcript):\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    return splitter.create_documents([transcript])\n",
    "\n",
    "# ------------------ Vector Store & Retriever  ------------------\n",
    "def generate_embeddings(chunks):\n",
    "    embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "    return FAISS.from_documents(chunks, embeddings)\n",
    "\n",
    "def retriever_docs(vector_store):\n",
    "    return vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})\n",
    "\n",
    "def format_docs(retrieved_docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "50de37cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ Imports ------------------\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import TypedDict, Annotated\n",
    "import re\n",
    "import os\n",
    "from langchain.prompts import PromptTemplate\n",
    "#os.environ[\"LANGCHAIN_PROJECT\"] = \"TubeTalkAI Testing\"\n",
    "\n",
    "# ------------------ Build LLM (Gemini) ------------------\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0)\n",
    "\n",
    "#--------------------Prompt Template----------------------\n",
    "template = \"\"\"\n",
    "You are the YouTuber from the video, directly answering the viewer’s question.\n",
    "\n",
    "Rules:\n",
    "1. ONLY use the transcript provided below.\n",
    "2. Give the answer in simple, clear sentences — without timestamps inside the text.\n",
    "3. ALWAYS return the exact timestamp (in seconds) from the transcript line you used.\n",
    "   - Do NOT round or estimate timestamps.\n",
    "   - If multiple transcript parts are relevant, return the most direct one.\n",
    "4. Do NOT add greetings, filler, or extra commentary.\n",
    "5. If the transcript does not answer, say: \"Sorry, I didn’t talk about that in this video.\"\n",
    "\n",
    "Transcript:\n",
    "{transcript}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Output format (for schema):\n",
    "- \"answer\": A list of 1–3 short strings that directly answer the question (no timestamps here).\n",
    "- \"timestamps\": The exact timestamp (in seconds) from the transcript where the answer was found.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"transcript\", \"question\"],\n",
    "    template=template,\n",
    ")\n",
    "# ------------------ Structured Output Schema ------------------\n",
    "class AnsandTime(BaseModel):\n",
    "    answer:str = Field(\n",
    "        description=\"Answers to user's question (do NOT include timestamps here)\"\n",
    "    )\n",
    "    timestamps: float = Field(\n",
    "        description=\"The time (in seconds) from where the answer is taken\"\n",
    "    )\n",
    "\n",
    "structured_model = model.with_structured_output(AnsandTime)\n",
    "\n",
    "# ------------------ ChatState ------------------\n",
    "class ChatState(TypedDict):\n",
    "    messages: Annotated[list[BaseMessage], \"add_messages\"]\n",
    "\n",
    "# ------------------ Chat Node ------------------\n",
    "def chat_node(state: ChatState):\n",
    "    # Extract user question from state\n",
    "    user_message = state[\"messages\"][-1].content  # last message is the user's input\n",
    "\n",
    "    # Fill the prompt\n",
    "    final_prompt = prompt.format(\n",
    "        transcript=context,   # <-- your transcript goes here\n",
    "        question=user_message\n",
    "    )\n",
    "\n",
    "    # Get structured output\n",
    "    response = structured_model.invoke(final_prompt)\n",
    "    ai_text = f\"{response.answer}\\nTimestamp: {response.timestamps}\"\n",
    "\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            state[\"messages\"][-1],  # include the HumanMessage again\n",
    "            AIMessage(content=ai_text)  # add the AI reply\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# ------------------ Build Graph ------------------\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "graph = StateGraph(ChatState)\n",
    "graph.add_node(\"chat_node\", chat_node)\n",
    "graph.add_edge(START, \"chat_node\")\n",
    "graph.add_edge(\"chat_node\", END)\n",
    "\n",
    "CONFIG = {'configurable': {'thread_id': \"newthread\"}}\n",
    "workflow =graph.compile(checkpointer = checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "638d3f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript Loaded: Hello all, my name is Krishna Nayak and (0.48) welcome to my YouTube channel. So guys, (2.56) today in this particular video, we are (4.96) going to go ahead and see the entire (7.12) road map to lear ...\n"
     ]
    }
   ],
   "source": [
    "# ------------------ Load YouTube Transcript ------------------\n",
    "youtube_input = \"https://www.youtube.com/watch?v=s3KnSb9b4Pk\"\n",
    "youtube_captions = load_transcript(youtube_input)\n",
    "print(\"Transcript Loaded:\", youtube_captions[:200], \"...\")\n",
    "\n",
    "# Split & Embed transcript\n",
    "chunks = text_splitter(youtube_captions)\n",
    "vector_store = generate_embeddings(chunks)\n",
    "retriever = retriever_docs(vector_store)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1298d821",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict = {\"human\": [], \"ai\": []}\n",
    "CONFIG = {'configurable': {'thread_id': \"newthread\"}}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "9d3e981c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user : what is this Video About?\n",
      "AI: This video is about the entire road map to learn AI in 2025.\n",
      "Timestamp: 7.12\n",
      "user : when should I learn Modern AI\n",
      "AI: Nowadays, I usually prefer the modern route.\n",
      "Timestamp: 413.44\n",
      "user : Should I learn modern AI After learning Traditional AI\n",
      "AI: If you want to get into the coding industry, you should definitely follow the traditional route, then go to the modern route, and then to the advanced route.\n",
      "Timestamp: 695.6\n"
     ]
    }
   ],
   "source": [
    "while True : \n",
    "    user_input = input(\"User : \")\n",
    "    if user_input == 'exit':\n",
    "        break\n",
    "    print(\"user :\", user_input)\n",
    "    retrieved_chunks = retriever.get_relevant_documents(user_input)\n",
    "    context = format_docs(retrieved_chunks)\n",
    "    result = workflow.invoke(\n",
    "            {'messages': [HumanMessage(content=user_input)]},\n",
    "            config=CONFIG,\n",
    "        )\n",
    "    for msg in result['messages']:\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            if msg.content not in output_dict['human']:\n",
    "                output_dict['human'].append(msg.content)\n",
    "        elif isinstance(msg, AIMessage):\n",
    "            if msg.content not in output_dict['ai']:\n",
    "                output_dict['ai'].append(msg.content)\n",
    "\n",
    "    print(\"AI:\", output_dict['ai'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "285a13a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"traditional route wherein you're (379.199) mastering everything like data science, (381.44) machine learning, CV and LP. This will (382.96) definitely be your base and on top of (385.44) that you are adding generative AI and (388.16) agentic AI skills. Okay. Now when I'm (390.24) also talking about generative AI and (394.0) agent AI skills, I'm also talking about (395.28) developing end to-end projects, doing (397.199) the deployment in cloud using some (399.12) amazing LLM ops tools, each and (401.12) everything. Okay. Now coming to the (402.88) second part which is the modern route (405.039) right nowadays if many of the people ask (406.8) me kish (409.6) which path should I probably go ahead (411.52) and take in order to learn AI nowadays I (413.44) usually prefer them modern route. Now (416.319) what is modern route? Here I will say (418.0) them hey go ahead and learn (420.24) generative AI first. (424.0) Okay. So here you go ahead and learn (426.479) about generative AI first. In\\n\\napplications. Now I (724.959) hope you are able to understand from (727.36) this particular road map how you should (730.0) basically go ahead and do this. If I (731.76) will say if you are a leader, if you are (733.76) a very experienced person just go ahead (735.519) and follow this modern route or either (737.36) you can also follow this advanced route (739.279) where you can start things parallelly (740.88) right but for freshers for the person (742.959) who have just started want to get into (745.36) the AI industry I would still suggest (747.68) follow this traditional route it will (750.32) take time but understand as you keep on (752.88) learning things you'll understand the (756.24) base of each and everything I have spent (758.16) around 6 to 7 years making videos and (760.56) I've covered almost everything in my (765.04) YouTube channel. Just imagine 2K plus (766.959) videos, right? 2Ks plus video. How many (768.959) people have actually got benefited out (771.839) of it?\\n\\nget into the coding (690.64) industry right coding industry then (692.24) definitely follow this pattern that is (695.6) traditional route then go to modern (697.519) route then go to advanced route now you (698.959) you make the decision you know what is (701.279) basically required see wherever you (703.92) learn something let's say if you are (706.399) going to this modern route some amount (707.76) of knowledge is will be required from (709.12) the traditional route also some basic (710.56) knowledge like NLP, machine learning, (712.56) deep learning, you know, that will (714.32) actually set up your base. But it is not (715.92) like you will be stopping over here. If (718.24) you start with this modern route, you'll (720.8) get blocked somewhere. No, here focus (722.48) more on building applications. Now I (724.959) hope you are able to understand from (727.36) this particular road map how you should (730.0) basically go ahead and do this. If I (731.76) will say if you are a\\n\\nthe modern route wherein you are trying (1192.0) to learn about generative AI. Now once (1193.679) you complete generative AI the third (1195.44) thing is about section three which is (1197.039) nothing but agentic AI. Never stop at (1198.64) generative AI because now people are (1200.72) focusing on developing agentic (1202.4) application agents right. So for this (1203.76) there is a separate road map. So in this (1206.559) road map you'll be able to see again how (1209.039) to start with the agentic AI. First of (1211.28) all again you need to know Python (1213.76) programming language some basic (1215.039) knowledge of machine learning natural (1216.24) language processing deep learning for (1217.52) NLP. Then you go over here with end to (1219.28) end project. See I've created generative (1221.679) AI tutorials with project agentic AI (1223.52) tutorials agentic AI playlist with (1225.76) different frameworks multimodel rags (1227.6) each and everything is basically covered\\n\\nthe technical (652.959) domain and they can quickly learn things (654.399) they can start this three right but (657.12) again the focus must be given in this (658.88) modern route more right whenever you go (661.279) ahead get time go ahead and learn the (663.68) basics of DS machine learning CV and LP (665.6) and continue this specific thing right (668.16) and this is nothing but this is (670.32) basically a comprehensive AI expert so (671.76) here you actually become a AI expert (674.32) right so this is what it is basically (678.24) happening see for leadership ship and (680.24) nontechnical people what I say usually (682.16) you can follow this three parallel uh (684.399) I'll not say for tech nontechnical (687.04) nontechnical can actually follow this if (688.64) you really want to get into the coding (690.64) industry right coding industry then (692.24) definitely follow this pattern that is (695.6) traditional route then go to modern (697.519) route then go to advanced route\""
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "1ee1db41",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1422482209.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[137]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31muser : what is this Video About\u001b[39m\n                        ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "user : what is this Video About\n",
    "AI: This video is about AI and geometry, and how a non-AI model was already better at geometry than most humans.\n",
    "Timestamp: 80.44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc17969d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This video is about AI and geometry, and how a non-AI model was already better at geometry than most humans.\n",
      "Timestamp: 80.44\n"
     ]
    }
   ],
   "source": [
    "print(output_dict['ai'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ab9281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='what is this Video About', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='This video is about AI and geometry, and how a non-AI model was already better at geometry than most humans.\\nTimestamp: 80.44', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['messages']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
