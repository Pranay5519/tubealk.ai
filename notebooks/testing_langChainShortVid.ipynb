{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff906a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='To learn Data Science, Machine Learning, Computer Vision, and NLP, it will take around 4 months if you devote 2 hours daily.\\nTimestamp: 563.839' additional_kwargs={} response_metadata={}\n",
      "Thread ID: 0633fdf0-b9a1-4fb6-a9b4-8c2bcc9e4fd3\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import sqlite3\n",
    "import uuid\n",
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# ------------------ Build LLM ------------------\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0)\n",
    "\n",
    "# ------------------ Structured Schema ------------------\n",
    "class AnsandTime(BaseModel):\n",
    "    answer: List[str] = Field(\n",
    "        description=\"Teaching assistant response broken into clear, informative segments. \"\n",
    "                    \"Each item should provide thorough explanation with context, examples, \"\n",
    "                    \"and clarification as needed for student comprehension. (No timestamps here)\"\n",
    "    )\n",
    "    timestamps: float = Field(description=\"The time (in seconds) from where the answer was taken\")\n",
    "\n",
    "structured_model = model.with_structured_output(AnsandTime)\n",
    "\n",
    "# ------------------ System Prompt ------------------\n",
    "system_prompt = \"\"\"\n",
    "You are the YouTuber from the video, directly answering the viewer’s question.\n",
    "\n",
    "Rules:\n",
    "1. ONLY use the transcript provided below.\n",
    "2. Give the answer in clear, simple bullet points (not paragraphs).\n",
    "3. Each bullet must include the exact timestamp (in seconds) from the transcript line used.\n",
    "   - Do NOT round or estimate timestamps.\n",
    "   - If multiple transcript parts are relevant, use separate bullets.\n",
    "4. Do NOT add greetings, filler, or extra commentary.\n",
    "5. If the transcript does not answer, say:\n",
    "   - \"Sorry, I didn’t talk about that in this video.\"\n",
    "6. Greet only if the viewer greets first.\n",
    "7. Always remember the viewer’s question when structuring the answer.\n",
    "\"\"\"\n",
    "\n",
    "# ------------------ Prompt Template ------------------\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(system_prompt),\n",
    "    HumanMessagePromptTemplate.from_template(\"Transcript:\\n{captions}\\n\\nQuestion:\\n{question}\")\n",
    "])\n",
    "\n",
    "# ------------------ SQLite Thread Persistence ------------------\n",
    "conn = sqlite3.connect(\"newDataBase1.db\", check_same_thread=False)\n",
    "\n",
    "def create_memory(thread_id: str):\n",
    "    \"\"\"Conversation memory saved per thread_id in SQLite.\"\"\"\n",
    "    return ConversationBufferMemory(\n",
    "        memory_key=\"chat_history\",\n",
    "        return_messages=True,\n",
    "        output_key=\"answer\",\n",
    "    )\n",
    "\n",
    "# ------------------ Chatbot Builder ------------------\n",
    "def build_chatbot(youtube_captions: str, thread_id: str = None):\n",
    "    \"\"\"Creates chatbot with memory (per thread).\"\"\"\n",
    "    if thread_id is None:\n",
    "        thread_id = str(uuid.uuid4())\n",
    "\n",
    "    memory = create_memory(thread_id)\n",
    "\n",
    "    chain = LLMChain(\n",
    "        llm=structured_model,\n",
    "        prompt=prompt,\n",
    "        memory=memory\n",
    "    )\n",
    "    return chain, thread_id\n",
    "\n",
    "# ------------------ Chat Function ------------------\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "def chat_with_bot(question: str, captions: str):\n",
    "    # Build messages\n",
    "    messages = [\n",
    "        SystemMessage(content=system_prompt),\n",
    "        HumanMessage(content=f\"Transcript:\\n{captions}\\n\\nQuestion:\\n{question}\")\n",
    "    ]\n",
    "\n",
    "    # Invoke structured LLM directly\n",
    "    response: AnsandTime = structured_model.invoke(messages)\n",
    "\n",
    "    ai_text = f\"{' '.join(response.answer)}\\nTimestamp: {response.timestamps}\"\n",
    "    return AIMessage(content=ai_text)\n",
    "\n",
    "# ------------------ Retrieve All Threads ------------------\n",
    "def retrieve_all_threads():\n",
    "    # since we are using SQLite directly, fetch all unique thread_ids\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT DISTINCT session_id FROM memory\")  # if using custom SQLite table\n",
    "    rows = cursor.fetchall()\n",
    "    return [r[0] for r in rows]\n",
    "\n",
    "# ------------------ Example ------------------\n",
    "if __name__ == \"__main__\":\n",
    "    captions = load_transcript(\"https://www.youtube.com/watch?v=s3KnSb9b4Pk\")\n",
    "    chain, thread_id = build_chatbot(captions)\n",
    "\n",
    "    user_question = \"How Long Does it takes to learn DataScience\"\n",
    "    answer = chat_with_bot( user_question, captions)\n",
    "    print(answer)\n",
    "    print(\"Thread ID:\", thread_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03be8225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='The first topic in Generative AI is Large Language Models (LLMs).\\nTimestamp: 1037.679' additional_kwargs={} response_metadata={}\n",
      "Thread ID: 0633fdf0-b9a1-4fb6-a9b4-8c2bcc9e4fd3\n"
     ]
    }
   ],
   "source": [
    "user_question = \"what is the first Topic In GenAI\"\n",
    "answer = chat_with_bot( user_question, captions)\n",
    "print(answer)\n",
    "print(\"Thread ID:\", thread_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
